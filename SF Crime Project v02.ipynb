{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import appropriate libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Set Numpy to print all lines of arrays\n",
    "np.set_printoptions(threshold='nan')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data into Pandas dataframe for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Here, we are going to extract features from the raw data, and create binary variables for the date variables and districts. This should give us data that is easily used in a Bernoulli Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dates' 'Category' 'Descript' 'DayOfWeek' 'PdDistrict' 'Resolution'\n",
      " 'Address' 'X' 'Y' 'DateTime' 'Year' 'Month' 'Day' 'Hour' 'SecondsDelta'\n",
      " 'Weekend' 2003L 2004L 2005L 2006L 2007L 2008L 2009L 2010L 2011L 2012L\n",
      " 2013L 2014L 2015L 'Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep'\n",
      " 'Oct' 'Nov' 'Dec' 1L 2L 3L 4L 5L 6L 7L 8L 9L 10L 11L 12L 13L 14L 15L 16L\n",
      " 17L 18L 19L 20L 21L 22L 23L 24L 25L 26L 27L 28L 29L 30L 31L 'Friday'\n",
      " 'Monday' 'Saturday' 'Sunday' 'Thursday' 'Tuesday' 'Wednesday' '12AM' '1AM'\n",
      " '2AM' '3AM' '4AM' '5AM' '6AM' '7AM' '8AM' '9AM' '10AM' '11AM' '12PM' '1PM'\n",
      " '2PM' '3PM' '4PM' '5PM' '6PM' '7PM' '8PM' '9PM' '10PM' '11PM' 'BAYVIEW'\n",
      " 'CENTRAL' 'INGLESIDE' 'MISSION' 'NORTHERN' 'PARK' 'RICHMOND' 'SOUTHERN'\n",
      " 'TARAVAL' 'TENDERLOIN']\n"
     ]
    }
   ],
   "source": [
    "# Extract new features here because it's easier in Pandas than NumPy\n",
    "def time_features(data):\n",
    "    data['DateTime'] = pd.to_datetime(data['Dates'])\n",
    "    data['Year'] = pd.DatetimeIndex(data['DateTime']).year\n",
    "    data['Month'] = pd.DatetimeIndex(data['DateTime']).month\n",
    "    data['Day'] = pd.DatetimeIndex(data['DateTime']).day\n",
    "    data['Hour'] = pd.DatetimeIndex(data['DateTime']).hour\n",
    "    data['SecondsDelta'] = (data.DateTime - pd.Timestamp('2013-01-01')) / np.timedelta64(1,'s')\n",
    "    data['Weekend'] = (data.DayOfWeek == \"Saturday\") | (data.DayOfWeek == \"Sunday\")\n",
    "    years = pd.get_dummies(data.Year)\n",
    "    months = pd.get_dummies(data.Month)\n",
    "    months.columns = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    days = pd.get_dummies(data.Day)\n",
    "    daysofweek = pd.get_dummies(data.DayOfWeek)\n",
    "    hours = pd.get_dummies(data.Hour)\n",
    "    hours.columns = ['12AM', '1AM', '2AM', '3AM', '4AM', '5AM',\n",
    "                     '6AM', '7AM', '8AM', '9AM', '10AM', '11AM',\n",
    "                     '12PM', '1PM', '2PM', '3PM', '4PM', '5PM',\n",
    "                     '6PM', '7PM', '8PM', '9PM', '10PM', '11PM']\n",
    "    districts = pd.get_dummies(data.PdDistrict)\n",
    "    new_data = pd.concat([data, years, months, days, daysofweek, hours, districts], axis=1)\n",
    "    return new_data\n",
    "\n",
    "data = time_features(data)\n",
    "test = time_features(test)\n",
    "\n",
    "print data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate labels\n",
    "labels = data.Category\n",
    "\n",
    "# Drop Category, Descript and Resolution columns since we cannot use them to predict\n",
    "train_data = data.drop(['Category', 'Descript', 'Resolution'], axis=1)\n",
    "train_names = train_data.columns.values.tolist()\n",
    "test_names = test.columns.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mini Train Data: (5000, 110)\n",
      "Mini Train Labels: (5000L,)\n",
      "Regular Train Data: (433991, 110)\n",
      "Regular Train Labels: (433991L,)\n",
      "Dev Data: (438991, 110)\n",
      "Dev Labels: (438991L,)\n",
      "Test Data: (884262, 111)\n",
      "Columns in use: ['Dates', 'DayOfWeek', 'PdDistrict', 'Address', 'X', 'Y', 'DateTime', 'Year', 'Month', 'Day', 'Hour', 'SecondsDelta', 'Weekend', 2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L, 2014L, 2015L, 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, 'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', 'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', 'SOUTHERN', 'TARAVAL', 'TENDERLOIN']\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to features.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "\n",
    "shuffle = np.random.permutation(np.arange(train_data.shape[0]))\n",
    "train_data = train_data.reindex(shuffle)\n",
    "labels = labels.reindex(shuffle)\n",
    "\n",
    "# Remove records where Y == 90\n",
    "train_data_clean = train_data[train_data.Y != 90]\n",
    "labels_clean = labels[train_data.Y != 90]\n",
    "num_examples = train_data_clean.shape[0]\n",
    "\n",
    "# Split the feature and label sets into train and dev sets\n",
    "mini_train_data = train_data_clean[:5000]\n",
    "mini_train_labels = labels_clean[:5000]\n",
    "\n",
    "reg_train_data = train_data_clean[5000:num_examples/2]\n",
    "reg_train_labels = labels_clean[5000:num_examples/2]\n",
    "\n",
    "dev_data = train_data_clean[num_examples/2:]\n",
    "dev_labels = labels_clean[num_examples/2:]\n",
    "\n",
    "test_data = test.copy()\n",
    "\n",
    "print \"Mini Train Data:\", mini_train_data.shape\n",
    "print \"Mini Train Labels:\", mini_train_labels.shape\n",
    "print \"Regular Train Data:\", reg_train_data.shape\n",
    "print \"Regular Train Labels:\", reg_train_labels.shape\n",
    "print \"Dev Data:\", dev_data.shape\n",
    "print \"Dev Labels:\", dev_labels.shape\n",
    "print \"Test Data:\", test_data.shape\n",
    "print \"Columns in use:\", train_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_submission(preds):\n",
    "    labels = [\"Id\",\"ARSON\",\"ASSAULT\",\"BAD CHECKS\",\"BRIBERY\",\"BURGLARY\",\"DISORDERLY CONDUCT\",\"DRIVING UNDER THE INFLUENCE\",\n",
    "              \"DRUG/NARCOTIC\",\"DRUNKENNESS\",\"EMBEZZLEMENT\",\"EXTORTION\",\"FAMILY OFFENSES\",\"FORGERY/COUNTERFEITING\",\n",
    "              \"FRAUD\",\"GAMBLING\",\"KIDNAPPING\",\"LARCENY/THEFT\",\"LIQUOR LAWS\",\"LOITERING\",\"MISSING PERSON\",\"NON-CRIMINAL\",\n",
    "              \"OTHER OFFENSES\",\"PORNOGRAPHY/OBSCENE MAT\",\"PROSTITUTION\",\"RECOVERED VEHICLE\",\"ROBBERY\",\"RUNAWAY\",\n",
    "              \"SECONDARY CODES\",\"SEX OFFENSES FORCIBLE\",\"SEX OFFENSES NON FORCIBLE\",\"STOLEN PROPERTY\",\"SUICIDE\",\n",
    "              \"SUSPICIOUS OCC\",\"TREA\",\"TRESPASS\",\"VANDALISM\",\"VEHICLE THEFT\",\"WARRANTS\",\"WEAPON LAWS\"]\n",
    "    head_str = ','.join(labels)\n",
    "\n",
    "    num_cats = len(labels)\n",
    "    \n",
    "    # Make a dummy row to append to\n",
    "    ids = np.arange(preds.shape[0])[np.newaxis].transpose()\n",
    "    \n",
    "    results = np.column_stack((ids, preds))\n",
    "\n",
    "    num_form = ['%6f'] * (num_cats - 1)\n",
    "    num_form.insert(0, '%d')\n",
    "    # Write results to csv\n",
    "    np.savetxt('sample.csv', results, fmt=num_form, delimiter=',', header=head_str, comments='')\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 99\n"
     ]
    }
   ],
   "source": [
    "features_to_use = [2003L, 2004L, 2005L, 2006L, 2007L, 2008L, 2009L, 2010L, 2011L, 2012L, 2013L, 2014L, 2015L, \n",
    "                   'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec', \n",
    "                   1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, \n",
    "                   16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 25L, 26L, 27L, 28L, 29L, 30L, 31L, \n",
    "                   'Friday', 'Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', \n",
    "                   '12AM', '1AM', '2AM', '3AM', '4AM', '5AM', '6AM', '7AM', '8AM', '9AM', '10AM', '11AM', \n",
    "                   '12PM', '1PM', '2PM', '3PM', '4PM', '5PM', '6PM', '7PM', '8PM', '9PM', '10PM', '11PM', \n",
    "                   'BAYVIEW', 'CENTRAL', 'INGLESIDE', 'MISSION', 'NORTHERN', 'PARK', 'RICHMOND', \n",
    "                   'SOUTHERN', 'TARAVAL', 'TENDERLOIN', 'X', 'Y'\n",
    "                   ]\n",
    "\n",
    "print \"Number of features:\", len(features_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 10.0}\n",
      "0.227776612879\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1f817198>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEVCAYAAAD3pQL8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niLYkcURERFv+Py4+FK2+kIW5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2bac5d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's see what the optimal alpha is for a Bernoulli NB model\n",
    "\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]}\n",
    "\n",
    "clf = GridSearchCV(BernoulliNB(), [params], scoring='accuracy')\n",
    "clf.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "\n",
    "print clf.best_params_\n",
    "print clf.best_score_\n",
    "\n",
    "best_alpha = clf.best_params_['alpha']\n",
    "\n",
    "accuracies = [clf.grid_scores_[i][1] * 100 for i in range(len(clf.grid_scores_))]\n",
    "\n",
    "plt.plot(np.log10(params['alpha']), accuracies, marker='o')\n",
    "plt.xlabel(\"Log(Alpha)\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we throw in 99 features (basically every feature we created), the accuracy is maximized when alpha = 10. However, the practical difference in accuracy levels is very small -- we got an improvement of 0.015% when changing alpha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 0.228248415116\n",
      "Log Loss: 2.56692611753\n"
     ]
    }
   ],
   "source": [
    "# How well does the Bernoulli NB model do with the selected alpha?\n",
    "\n",
    "bnb = BernoulliNB(alpha=best_alpha)\n",
    "bnb.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "bnb_probs = bnb.predict_proba(test_data[features_to_use])\n",
    "print \"BernoulliNB accuracy:\", bnb.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, bnb.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 0.227774601302\n",
      "Log Loss: 2.56854223539\n"
     ]
    }
   ],
   "source": [
    "# Maybe bagging the Bernoulli NB model does us some good\n",
    "\n",
    "bnb_bag = BaggingClassifier(BernoulliNB(alpha=best_alpha), max_features=0.8, max_samples = 0.8)\n",
    "bnb_bag.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "bnb_bag_probs = bnb_bag.predict_proba(test_data[features_to_use])\n",
    "print \"BernoulliNB accuracy:\", bnb_bag.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, bnb_bag.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does not look like bagging the Bernoulli NB model is making any significant improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy: 0.187010277342\n",
      "Log Loss: 2.77445906464\n"
     ]
    }
   ],
   "source": [
    "# Perhaps doing some dimensionality reduction will help us\n",
    "\n",
    "pca = PCA(n_components = 70)\n",
    "pca_train_data = pca.fit_transform(reg_train_data[features_to_use])\n",
    "pca_dev_data = pca.transform(dev_data[features_to_use])\n",
    "pca_test_data = pca.transform(test_data[features_to_use])\n",
    "\n",
    "colors = [\"#1f77b4\",\"#2ca02c\",\"#7f7f7f\",\"#8c564b\",\"#9edae5\",\n",
    "          \"#17becf\",\"#98df8a\",\"#9467bd\",\"#aec7e8\",\"#bcbd22\",\n",
    "          \"#c5b0d5\",\"#c7c7c7\",\"#c49c94\",\"#d62728\",\"#dbdb8d\",\n",
    "          \"#e377c2\",\"#f7b6d2\",\"#ff7f0e\",\"#ff9896\",\"#ffbb78\"]\n",
    "\n",
    "#plt.scatter(pca_train_data[:, 0], pca_train_data[:, 1], c = colors, s = 50)\n",
    "\n",
    "bnb2 = BernoulliNB()\n",
    "bnb2.fit(pca_train_data, reg_train_labels)\n",
    "bnb2_probs = bnb2.predict_proba(pca_test_data)\n",
    "print \"BernoulliNB accuracy:\", bnb2.score(pca_dev_data, dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, bnb2.predict_proba(pca_dev_data)) \n",
    "\n",
    "# It doesn't seem that using PCA is giving us any better results than just the straight NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.169503261781\n",
      "Log Loss: 25.9921985239\n"
     ]
    }
   ],
   "source": [
    "# Let's try a decision tree\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "dt_probs = dt.predict_proba(test_data[features_to_use])\n",
    "print \"Decision Tree accuracy:\", dt.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, dt.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.178657658807\n",
      "Log Loss: 17.526350391\n"
     ]
    }
   ],
   "source": [
    "# Let's try a random forest\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "rf_probs = rf.predict_proba(test_data[features_to_use])\n",
    "print \"Random Forest accuracy:\", rf.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, rf.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's try and find the optimal C for logistic regression\n",
    "cs = [0.001,  0.005, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10]\n",
    "#cs = np.arange(0.1, 1.0, 0.1)\n",
    "parameters = dict(C = cs)\n",
    "\n",
    "clf = GridSearchCV(LogisticRegression(), parameters, scoring='accuracy')\n",
    "clf.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "print \"Default value of C is 1.0\"\n",
    "print \"Optimal value of C is\", str(clf.best_params_['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.226161811973\n",
      "Log Loss: 2.68228615201\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with optimized C\n",
    "\n",
    "lr = LogisticRegression(C=0.001)\n",
    "lr.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "lr_probs = lr.predict_proba(test_data[features_to_use])\n",
    "print \"Logistic Regression accuracy:\", lr.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, lr.predict_proba(dev_data[features_to_use])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 0.256802531259\n",
      "Log Loss: 2.48932932693\n"
     ]
    }
   ],
   "source": [
    "# Try Gradient Boosting\n",
    "\n",
    "grad_boost = GradientBoostingClassifier()\n",
    "grad_boost.fit(reg_train_data[features_to_use], reg_train_labels)\n",
    "print \"Logistic Regression accuracy:\", grad_boost.score(dev_data[features_to_use], dev_labels)\n",
    "print \"Log Loss:\", log_loss(dev_labels, grad_boost.predict_proba(dev_data[features_to_use])) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_boost_probs = grad_boost.predict_proba(test_data[features_to_use])\n",
    "create_submission(grad_boost_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try to average the probabilities of the NB and LR classifiers\n",
    "\n",
    "#avg_probs = (bnb.predict_proba(dev_data[features_to_use]) + lr.predict_proba(dev_data[features_to_use])) / 2\n",
    "avg_probs = (bnb_probs + lr_probs) / 2\n",
    "#print \"Log Loss:\", log_loss(dev_labels, avg_probs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "create_submission(avg_probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
